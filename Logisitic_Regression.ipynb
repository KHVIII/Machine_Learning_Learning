{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2-final"
    },
    "colab": {
      "name": "Logisitic Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "MYVEgla9mYOB",
        "d-uh4KnvmYOD"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "BP8ER5IwmYNr"
      },
      "source": [
        "# Import Important Libraries\n",
        "import sklearn\n",
        "from sklearn.datasets import load_breast_cancer # taking included data set from Sklearn http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html\n",
        "from sklearn.linear_model import LogisticRegression # importing Sklearn's logistic regression's module\n",
        "from sklearn import preprocessing # preprossing is what we do with the data before we run the learning algorithm\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "import numpy as np\n",
        "# import math\n",
        "import math\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLP52cVdmYNt"
      },
      "source": [
        "# Loading the data set.\n",
        "\n",
        "In the below code cell, you will load the data from sklearn using the method given. Check import statements and use the given function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "q722FUPtmYNt"
      },
      "source": [
        "\n",
        "cancer = load_breast_cancer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVyql1YSmYNv",
        "outputId": "b60516d6-a075-45f9-9af6-6f6993febb87"
      },
      "source": [
        "# VERIFY - Print the shape of data and target\n",
        "print('Q01 - cancer.target.shape: ', cancer.target.shape)\n",
        "print('Q01 - cancer.data.shape: ', cancer.data.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q01 - cancer.target.shape:  (569,)\n",
            "Q01 - cancer.data.shape:  (569, 30)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wh4CdotJmYNw"
      },
      "source": [
        "# Data Pre-Processing\n",
        "Scale before splitting the data into train and test since we will be using gradient ascent. \n",
        "* Use `preprocessing` to scale the data. \n",
        "* Assign the target of cancer to variable `y (<np.ndarray>)`.\n",
        "* Use `train_test_split` to split the data (`75% train` and `25% test`) to `X_train`, `X_test`, `y_train`, `y_test` with `random_state` of 42\n",
        "* Reshape `y_train` into 2D array `y_2d_train` and `y_test` into 2D array `y_2d_test`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "khIqQZCsmYNx"
      },
      "source": [
        "\n",
        "X_unscaled = cancer.data.copy()\n",
        "y = cancer.target.copy()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_unscaled, y, random_state=42)\n",
        "\n",
        "#scaling x \n",
        "scaler = preprocessing.StandardScaler()\n",
        "X_train= scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "y_2d_train = y_train.reshape(y_train.shape[0],1)\n",
        "y_2d_test = y_test.reshape(y_test.shape[0],1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7-z6FWPmYNz",
        "outputId": "3cef88b4-64a0-4657-8c9f-eeec3566eecb"
      },
      "source": [
        "# VERIFY - Print the shape of X_train and y_2d_train\n",
        "print('Q02 - X_train.shape: ', X_train.shape)\n",
        "print('Q02 - y_2d_train.shape: ', y_2d_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q02 - X_train.shape:  (426, 30)\n",
            "Q02 - y_2d_train.shape:  (426, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOSdZvs1mYNz",
        "outputId": "0ab16783-b3c1-4edc-a324-e867a5f55ae3"
      },
      "source": [
        "# VERIFY - Printing the names of all the features\n",
        "print('Q02 - cancer.feature_names: ', cancer.feature_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q02 - cancer.feature_names:  ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
            " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
            " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
            " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
            " 'smoothness error' 'compactness error' 'concavity error'\n",
            " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
            " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
            " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
            " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CC4k3CnrmYN0"
      },
      "source": [
        "# Implementing Logistic Regression Using Gradient Ascent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "MClHHowQmYN0"
      },
      "source": [
        "# Write the sigmoid function\n",
        "def sigmoid(z):\n",
        "    result = 1/(1+math.exp(-z))\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PQN3vMxmYN1",
        "outputId": "8568b53d-fade-4664-f8bf-b86e2f90ab73"
      },
      "source": [
        "# VERIFY - Sigmoid of 0 should be equal to half\n",
        "print('Q03 - sigmoid(0): ', sigmoid(0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q03 - sigmoid(0):  0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbTyH5CimYN1"
      },
      "source": [
        "# Append a column of ones to X_train\n",
        "# ones is a  vector of shape n,1\n",
        "ones = np.ones((X_train.shape[0],1))\n",
        "# Append a column of ones in the beginning of X_train an save in variable X_train_1(<np.ndarray>).\n",
        "X_train_1 = np.hstack((ones,X_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OROl3urCmYN2",
        "outputId": "26a1e4f0-fe8c-48e2-dd9c-8897757481da"
      },
      "source": [
        "# VERIFY\n",
        "print('Q04 - X_train_1.shape: ', X_train_1.shape)\n",
        "print('Q04 - X_train_1: ', X_train_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q04 - X_train_1.shape:  (426, 31)\n",
            "Q04 - X_train_1:  [[ 1.         -0.34913849 -1.43851335 ... -0.91671059 -0.92508585\n",
            "  -0.80841115]\n",
            " [ 1.         -0.20468665  0.31264011 ...  1.43655962  1.14955889\n",
            "   1.56911143]\n",
            " [ 1.         -0.32931176 -0.21507235 ... -0.7237126   0.53496977\n",
            "  -0.61934827]\n",
            " ...\n",
            " [ 1.          0.04739597 -0.56293662 ... -1.23262438 -0.68282718\n",
            "  -1.261137  ]\n",
            " [ 1.         -0.04040808  0.09966199 ...  1.08847951  0.48944465\n",
            "   1.26159953]\n",
            " [ 1.         -0.5502381   0.31264011 ... -0.59582424 -0.29911546\n",
            "  -0.82948141]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lA81cQo7mYN2"
      },
      "source": [
        "# Initialize Parameter Vector w to a zero matrix with shape (X_train_1.shape[1],1)\n",
        "w_init = np.zeros((X_train_1.shape[1],1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTGjTfEzmYN3",
        "outputId": "024d819f-2c8e-4b91-c188-8ee91f420a41"
      },
      "source": [
        "# VERIFY\n",
        "print('Q05 - w_init.shape: ', w_init.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q05 - w_init.shape:  (31, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "A0IGXwt2mYN3"
      },
      "source": [
        "# Write the hypothesis function\n",
        "#I am heavily assuming what you want is the Possibility function, not the actual yhat which is gonna be either 0 or 1, so I am writing that instead.\n",
        "def hypothesis(X_train_1, w):\n",
        "    v_sigmoid = np.vectorize(sigmoid)\n",
        "    y_hat = v_sigmoid(np.dot(X_train_1,w))\n",
        "    return y_hat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1sszEZKmYN4"
      },
      "source": [
        "# Compute y_hat(<np.ndarray>) using X_train_1 and w_init\n",
        "y_hat_init = hypothesis(X_train_1,w_init)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GblNpRy_mYN5"
      },
      "source": [
        "# Likelihood Function.\n",
        "Write the code to calculate the log likelihood as discussed in the class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "o8iKNucDmYN5"
      },
      "source": [
        "# Write the log likelihood function\n",
        "def likelihood(X_tr, y_tr, w, n):\n",
        "    y_hat = hypothesis(X_tr,w)\n",
        "    likelihood = ((y_tr * np.log(y_hat)) + ((1-y_tr) * np.log(1-y_hat))).sum() \n",
        "    return likelihood"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZCiyNHimYN5",
        "outputId": "0b4576fb-5243-4262-fbc4-12d89ca7b371"
      },
      "source": [
        "# VERIFY - The value should be equal to -295.2806989185367 using X_train_1, y_2d_train, w, X_train_1.shape[0].\n",
        "print('Q08 - likelihood: ', likelihood(X_train_1, y_2d_train, w_init, X_train_1.shape[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q08 - likelihood:  -295.2806989185367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pq0odkhQpnry",
        "outputId": "1974008b-5f4e-47ca-ac7d-01aa1ed96cc3"
      },
      "source": [
        "#Maximum Likelihood function with lasso regulization\n",
        "def lasso_likelihood(X_tr,y_tr, w, n, l):\n",
        "    y_hat = hypothesis(X_tr,w)\n",
        "    likelihood = ((y_tr * np.log(y_hat)) + ((1-y_tr) * np.log(1-y_hat))).sum() \n",
        "    lasso_likelihood = likelihood * (1/n) - l*(np.absolute(w[1:,:])).sum()\n",
        "    return lasso_likelihood\n",
        "\n",
        "def ridge_likelihood(X_tr,y_tr, w, n, l):\n",
        "    y_hat = hypothesis(X_tr,w)\n",
        "    likelihood = ((y_tr * np.log(y_hat)) + ((1-y_tr) * np.log(1-y_hat))).sum() \n",
        "    ridge_likelihood = likelihood * (1/n) - l*(np.square(w[1:,:])).sum()\n",
        "    return ridge_likelihood\n",
        "\n",
        "def derivative_ridge_likelihood(X_tr,y_tr,w, n, l):\n",
        "    y_hat = hypothesis(X_tr,w)\n",
        "    zeros = np.zeros((1,w.shape[1]))\n",
        "    derivative = (np.dot(X_train_1.T, (y_2d_train - y_hat))) * (1/n) - np.vstack((zeros,(2*l*w[1:,:])))\n",
        "    return derivative\n",
        "\n",
        "def Gradient_Ascent_Ridge(X_train_1, y_2d_train, learning_rate, l, num_iters):\n",
        "    # Number of training examples.\n",
        "    N = X_train_1.shape[0]\n",
        "    # Initialize w(<np.ndarray>). Zeros vector of shape X_train.shape[1],1\n",
        "    w = np.zeros((X_train_1.shape[1],1))\n",
        "    # Initiating list to store values of likelihood(<list>) after few iterations.\n",
        "    ridge_likelihood_values = []\n",
        "    for i in range(num_iters):\n",
        "        y_hat = hypothesis(X_train_1,w)\n",
        "        gradient = (np.dot(X_train_1.T, (y_2d_train - y_hat)))*(1/N) - (2*l*w)\n",
        "        # Updating Parameters\n",
        "        w = w + learning_rate * gradient / N\n",
        "        if (i % 100) == 0:\n",
        "            ridge_likelihood_values.append(likelihood(X_train_1,y_2d_train,w,N))\n",
        "        \n",
        "    return w, ridge_likelihood_values\n",
        "\n",
        "#I am going to use sklearn library to do this\n",
        "def cross_fold(X_unscaled, y, nfold):\n",
        "    npen = 20\n",
        "    C_test = np.logspace(-2,2,npen)\n",
        "\n",
        "    kf = KFold(n_splits=nfold,shuffle=True)\n",
        "    err_rate = np.zeros((npen,nfold))\n",
        "    num_nonzerocoef = np.zeros((npen,nfold))\n",
        "    \n",
        "    logreg = LogisticRegression(solver='liblinear', penalty='l2',warm_start=True)\n",
        "\n",
        "    # Loop over the folds in the cross-validation\n",
        "    for ifold, Ind in enumerate(kf.split(X_unscaled)):        \n",
        "                \n",
        "        # Get training and test data\n",
        "        Itr, Its = Ind\n",
        "        Xtr = X_unscaled[Itr,:]\n",
        "        ytr = y[Itr]\n",
        "        Xts = X_unscaled[Its,:]\n",
        "        yts = y[Its]\n",
        "        \n",
        "        scaler_KFold = preprocessing.StandardScaler()\n",
        "        Xtr= scaler_KFold.fit_transform(Xtr)\n",
        "        Xts = scaler_KFold.transform(Xts)\n",
        "        \n",
        "        # Loop over penalty levels\n",
        "        for ipen, c in enumerate(C_test):\n",
        "            \n",
        "            # Set the penalty level        \n",
        "            logreg.C= c\n",
        "        \n",
        "            # Fit a model on the training data\n",
        "            logreg.fit(Xtr, ytr)\n",
        "        \n",
        "            # Predict the labels on the test set.\n",
        "            yhat = logreg.predict(Xts)\n",
        "            \n",
        "            # Measure the accuracy\n",
        "            err_rate[ipen,ifold] = np.mean(yhat != yts)\n",
        "            num_nonzerocoef[ipen,ifold]=np.sum(abs(logreg.coef_)>0.001)\n",
        "\n",
        "        print(\"Fold %d\" % ifold)\n",
        "        \n",
        "    err_mean = np.mean(err_rate, axis=1)\n",
        "    num_nonzerocoef_mean = np.mean(num_nonzerocoef, axis=1)\n",
        "    err_se = np.std(err_rate,axis=1)/np.sqrt(nfold-1)\n",
        "    plt.errorbar(np.log10(C_test), err_mean, marker='o',yerr=err_se)\n",
        "    plt.ylim([0.02,0.05])\n",
        "    plt.grid()\n",
        "    plt.xlabel('log10(C)')\n",
        "    plt.ylabel('Error rate')\n",
        "\n",
        "    imin = np.argmin(err_mean)\n",
        "\n",
        "    print(\"The minimum test error rate = %12.4e, SE=%12.4e\" % (err_mean[imin], err_se[imin]))\n",
        "    print(\"The C value corresponding to minimum error = %12.4e\" % (C_test[imin]))\n",
        "\n",
        "\n",
        "cross_fold(X_unscaled,y,5)\n",
        "#print(lasso_likelihood(X_train_1,y_2d_train,w_init,X_train_1.shape[0],0.1))\n",
        "#print(ridge_likelihood(X_train_1,y_2d_train,w_init,X_train_1.shape[0],0.1))\n",
        "#print(derivative_ridge_likelihood(X_train_1,y_2d_train,w_init,X_train_1.shape[0],0.1))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.6931471805599453\n",
            "-0.6931471805599453\n",
            "[[ 0.12910798]\n",
            " [-0.34474631]\n",
            " [-0.20171358]\n",
            " [-0.35116594]\n",
            " [-0.33338291]\n",
            " [-0.17892023]\n",
            " [-0.28171086]\n",
            " [-0.33045085]\n",
            " [-0.37415222]\n",
            " [-0.17498941]\n",
            " [ 0.01343712]\n",
            " [-0.26310996]\n",
            " [-0.00856968]\n",
            " [-0.25511148]\n",
            " [-0.24845598]\n",
            " [ 0.02307273]\n",
            " [-0.12678715]\n",
            " [-0.11841836]\n",
            " [-0.19111932]\n",
            " [-0.01233897]\n",
            " [-0.02511409]\n",
            " [-0.36815402]\n",
            " [-0.22683885]\n",
            " [-0.37174116]\n",
            " [-0.34641029]\n",
            " [-0.20211322]\n",
            " [-0.27815643]\n",
            " [-0.32049309]\n",
            " [-0.38009885]\n",
            " [-0.21383914]\n",
            " [-0.14011838]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpYWHKi7mYN6"
      },
      "source": [
        "# Gradient Ascent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "SyLQx6EQmYN6"
      },
      "source": [
        "# Write the gradient ascent function\n",
        "def Gradient_Ascent(X_train_1, y_2d_train, learning_rate, num_iters):\n",
        "    # Number of training examples.\n",
        "    N = X_train_1.shape[0]\n",
        "    # Initialize w(<np.ndarray>). Zeros vector of shape X_train.shape[1],1\n",
        "    w = np.zeros((X_train_1.shape[1],1))\n",
        "    # Initiating list to store values of likelihood(<list>) after few iterations.\n",
        "    likelihood_values = []\n",
        "    for i in range(num_iters):\n",
        "        y_hat = hypothesis(X_train_1,w)\n",
        "        error = ... #I do not know what type of error you want from me, F1 score? I am not doing this since we do not use this for the function \n",
        "        gradient = (np.dot(X_train_1.T, (y_2d_train - y_hat)))\n",
        "        # Updating Parameters\n",
        "        w = w + learning_rate * gradient / N\n",
        "        if (i % 100) == 0:\n",
        "            likelihood_values.append(likelihood(X_train_1,y_2d_train,w,N))\n",
        "        \n",
        "    return w, likelihood_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3Iw9WvUmYN6"
      },
      "source": [
        "learning_rate = 0.001\n",
        "num_iters = 50000\n",
        "# Calculate w and likelihood values using Gradient_Ascent with X_train_1, y_2d_train\n",
        "w, likelihood_values = Gradient_Ascent(X_train_1,y_2d_train,learning_rate,num_iters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDARK6C1mYN-"
      },
      "source": [
        "# Plotting Likelihood v/s Number of Iterations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "tg5utED2mYN-",
        "outputId": "b5315c15-1723-47b3-fb6e-846f1e7e12ac"
      },
      "source": [
        "# Run this cell to plot Likelihood v/s Number of Iterations.\n",
        "iters = np.array(range(0,num_iters,100))\n",
        "plt.plot(iters,likelihood_values,'.-',color='green')\n",
        "plt.xlabel('Number of iterations')\n",
        "plt.ylabel('Likelihood')\n",
        "plt.title(\"Likelihood vs Number of Iterations.\")\n",
        "plt.grid()\n",
        "plt.show(block=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOll7OW4mYN_"
      },
      "source": [
        "You should see the likelihood increasing as number of Iterations increase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "cSN3EOr3mYN_"
      },
      "source": [
        "#since we are now predicting, instead of the probability, I will produce y_hat\n",
        "\n",
        "##def predict(X_train_1, w):\n",
        "##    def check(x):\n",
        "##        if (x>0):\n",
        "##            return (1)\n",
        "##        elif (x == 0):\n",
        "##            return (np.random.randint(0,2))\n",
        "##        else:\n",
        "##            return 0\n",
        "##    check_v = np.vectorize(check) \n",
        "##    y_hat = check_v(np.dot(X_train_1,w))\n",
        "##    return y_hat\n",
        "\n",
        "def predict(X_train_1,w):\n",
        "    v_sigmoid = np.vectorize(sigmoid)\n",
        "    y_hat = v_sigmoid(np.dot(X_train_1,w))\n",
        "    return y_hat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdSHv1ywmYN_"
      },
      "source": [
        "# Preidct y_hat using X_train_1 and w you just calculated\n",
        "y_hat = predict(X_train_1,w)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "72j8_V0UmYOA"
      },
      "source": [
        "# Write the precision_recall function\n",
        "def precision_recall(y_hat, y, threshold):  \n",
        "    # Before finding precision or recall, you have to convert y_hat into a vector of zeros and ones named y_hat_binary using threshold.\n",
        "    # Values in y_hat > threshold should be equal to 1 and others should be 0.\n",
        "    y_hat_binary = np.copy(y_hat)\n",
        "    # Convert values in y_hat_binary to binary values below\n",
        "    def check(x):\n",
        "        if (x>threshold):\n",
        "            return (1)\n",
        "            ##elif (x == threshold):\n",
        "            ##    return (np.random.randint(0,2))\n",
        "        else:\n",
        "            return (0)\n",
        "    check_v = np.vectorize(check) \n",
        "    \n",
        "    y_hat_binary = check_v(y_hat_binary)\n",
        "    #print(y_hat_binary)\n",
        "\n",
        "    # Calculate false positive and false negative using false difference\n",
        "    # HINT: false different can be calculated by subtracting hypothesis from actual value\n",
        "    # HINT: if done correctly, false_pos should be 4 and false_neg should be 2\n",
        "    false_difference = y_hat_binary - y\n",
        "    false_pos = (false_difference == 1).sum()\n",
        "    false_neg = (false_difference == -1).sum()\n",
        "\n",
        "\n",
        "\n",
        "    all_trues = np.ones((y.shape[0], 1)) \n",
        "    # Calculate true positive using all_trues and true difference\n",
        "    # HINT: true different can be calculated by subtracting sum of hypothesis and actual value from all trues\n",
        "    # HINT: if done correctly, true_pos should be 266\n",
        "    true_difference = y_hat_binary + y - all_trues\n",
        "    true_pos = (true_difference == 1).sum()\n",
        "\n",
        "\n",
        "    precision = true_pos / (true_pos+false_pos)\n",
        "    recall = true_pos / (true_pos+false_neg)\n",
        "    return precision,recall"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVjRvmx7mYOA",
        "outputId": "10e6ff00-442e-4b4e-9a5b-7054680b464d"
      },
      "source": [
        "# Calculate precision and recall using y_hat, y_2d_train and threshold of 0.5\n",
        "precision, recall = precision_recall(y_hat,y_2d_train,0.5)\n",
        "print('Q14 - precision: ', precision)\n",
        "print('Q14 - recall: ', recall)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q14 - precision:  0.9851851851851852\n",
            "Q14 - recall:  0.9925373134328358\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oLEk5HjmYOB"
      },
      "source": [
        "# Write the f_score function\n",
        "def f_score(precision, recall):\n",
        "    score = 2* (precision*recall)/(precision+recall)\n",
        "    return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYVEgla9mYOB"
      },
      "source": [
        "# Fitting Model using Sk Learn Library. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "uc9N2GRlmYOB"
      },
      "source": [
        "logreg =  LogisticRegression(C=100000000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPUct1OemYOC",
        "outputId": "63385e43-c5f0-4396-9575-38f1cd2befa9"
      },
      "source": [
        "# Fit the model\n",
        "# Don't use matrix X_train_1. Instead, use x_train.\n",
        "logreg.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=100000000, class_weight=None, dual=False,\n",
              "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
              "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWc1GwNbmYOC",
        "outputId": "82d465ed-39f7-4522-89d4-dfcec1b6a9a2"
      },
      "source": [
        "# Find the predicted values on training set using logreg.predict\n",
        "y_hat_logreg = logreg.predict(X_train)\n",
        "# Find the accuracy achieved on training set using logreg.score and y_train as type of int\n",
        "acc_logreg = logreg.score(X_train,y_train) \n",
        "\n",
        "print(\"Q18 - Accuracy on training data = %f\" % acc_logreg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q18 - Accuracy on training data = 1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "bovpwP4kmYOC"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "<!--\n",
        "BEGIN QUESTION\n",
        "name: Q19\n",
        "manual: true\n",
        "points:\n",
        "  each: 1\n",
        "-->"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DA5CYYEmYOD"
      },
      "source": [
        "# Print out all the coefficients\n",
        "w_logreg = logreg.coef_\n",
        "intercept_logreg = logreg.intercept_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "working-noise"
      },
      "source": [
        "<!-- END QUESTION -->"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsHiWX0GmYOD",
        "outputId": "a7af8fbc-a657-408c-c02e-703cd881b8bd"
      },
      "source": [
        "# VERIFY - Compare the parameters computed by logreg model and gradient ascent. They should be nearly same.\n",
        "print('Q19 - w_logreg: ', w_logreg)\n",
        "print('Q19 - intercept_logreg: ', intercept_logreg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q19 - w_logreg:  [[  22.20354939  -21.44100978   59.16839412    1.2115979   -42.19697283\n",
            "   360.63887807 -106.3087013  -289.5216613    96.40386209 -194.28626767\n",
            "  -369.06429646   58.89312117   67.54079586 -215.07334324  -61.69597975\n",
            "   -88.60037689   61.79893125 -123.45994937  151.76554756  248.38541764\n",
            "  -133.50997508 -157.07474867   87.07454329 -136.95118586  102.92812654\n",
            "    94.88367681 -274.99164994  -62.66130469 -268.3824686     8.12051949]]\n",
            "Q19 - intercept_logreg:  [-44.50369833]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-uh4KnvmYOD"
      },
      "source": [
        "# Performance Metrics:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBfAdmBTmYOD"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "# Find Precision, recall and fscore using precision_recall_fscore_support nethod of sklearn\n",
        "# Using y_train and y_hat_logreg\n",
        "temp = precision_recall_fscore_support(y_train,y_hat_logreg)\n",
        "prec = temp[0]\n",
        "recal = temp[1]\n",
        "fscore = temp[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAeb3L3xmYOE",
        "outputId": "73ec117d-2560-4742-dd13-0e910551be48"
      },
      "source": [
        "# VERIFY\n",
        "print('Q20 - prec: ', prec)\n",
        "print('Q20 - recal: ', recal)\n",
        "print('Q20 - fscore: ', fscore)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q20 - prec:  [1. 1.]\n",
            "Q20 - recal:  [1. 1.]\n",
            "Q20 - fscore:  [1. 1.]\n"
          ]
        }
      ]
    }
  ]
}